
![](https://i.imgur.com/FlcQgWT.png)
- SST = Sum of Squares total
- SSE = Sum of Squares Error
- Yhat = Predicted Y value
- If its a lower sum of squares then we say that X has some variation in Y


![](https://i.imgur.com/LmhyHS9.png)
- Independent variable = X
- Dependent Variable = Y

![](https://i.imgur.com/kYSlm4n.png)
- If bhat1 > 0 then rxy > 0
- Standard deviations cannot be negative so the sign of b is determined by the numerator

**Interpreting the intercept:**
![](https://i.imgur.com/zGJs6py.png)

**Example around 29 minutes:**

![](https://i.imgur.com/tkPcnfd.png)
- Has to be linear
- Variance of the error needs to be the same for all observations 
- The pairs of x and y are independent

**Normality:**
![](https://i.imgur.com/f1CVVwt.png)

**Quiz:**
![](https://i.imgur.com/6rd0efE.png)
![](https://i.imgur.com/pUUrEjb.png)
![](https://i.imgur.com/rTwsRmi.png)


**Analysis of Variance:**

![](https://i.imgur.com/S1Degta.png)
- Makes sense to order that way to remember the equations
- Total sum of Squares (SST)
- Sum of Squared Errors (SSE)
- Regression sum of Squares (SSR)
- SST = SSE + SSR


![](https://i.imgur.com/eBjqIEE.png)
- R^2 is a measure of fit not a statistical test
- Use a F test for this
- IV = Independent variable



![](https://i.imgur.com/haziDGf.png)
- SEE = Standard Error of the Estimate
- Measures the standard deviation of the error terms

![](https://i.imgur.com/WjkPw1v.png)
- SEE = Standard error of the Estimate 

**Example:**

![](https://i.imgur.com/ZgSiTEv.png)
![](https://i.imgur.com/srklTUC.png)


**Hypothesis Tests of b^:**

![](https://i.imgur.com/VE2Owla.png)
- Regression Coefficient 
- df = n - (K+1) (= n - 2)



![](https://i.imgur.com/3TjzWI8.png)
- IND = indicator variable

![](https://i.imgur.com/IjPkSdP.png)
**Example 6:**

![](https://i.imgur.com/4eXuwbf.png)
![](https://i.imgur.com/j88fll4.png)
![](https://i.imgur.com/BlfMVgA.png)


**Quiz:**

![](https://i.imgur.com/ua7TjCo.png)
![](https://i.imgur.com/Yue0pZD.png)
![](https://i.imgur.com/LvGVfI1.png)


**Prediction Interval (or CI) for Y^:**

![](https://i.imgur.com/qCSICP7.png)
- SEE = Standard Error of the Estimate
![](https://i.imgur.com/ZtK7bFB.png)
**Example 7:**

![](https://i.imgur.com/0abSKRE.png)
![](https://i.imgur.com/i3KhJFm.png)
![](https://i.imgur.com/PpuHNIx.png)


**Log Linear Model:**
- Useful for a time series model
- Measures a relative change in y for an absolute change in x
- ln is on left side of the equation

**Linear Log Model:**
- Absolute change in y for relative change in x
- ln is on the right side of the equation
- Used when y and x are significantly different in scale
- The "Relative change" is the side with the ln
-See Below
![](https://i.imgur.com/mGpmiEl.png)

**Log Log Model:**
- Relative change in Yi for a relative change in Xi
![](https://i.imgur.com/YigWGPE.png)


**Seminar- Regression using FRED and Excel:**

- Cool video to show you how to get data from FRED and interpret stuff learned
